{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21b9cdffef93ded4706cf9e69a091add5897d633",
    "id": "LBydBHZl7fqa"
   },
   "source": [
    "# Fraud Detection with Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c96ae50f9b6526183014fd6a05e63a154519e6f",
    "id": "40TkjvAJ7fqa"
   },
   "source": [
    "- VAE는 vanilla 오토인코더에 비해 훨씬 나은 성능의 이상탐지(anomaly detection) 성능을 제공합니다. 실험을 통해 우리는 기존의 AE는 너무 큰 bottleneck을 가지면 identity function이 되며 이상탐지 성능이 떨어지는 것에 반해, VAE는 bottleneck의 크기가 커질수록 이상탐지 성능이 오르는 효과를 갖는 것을 확인할 수 있습니다. 따라서 AE 기반의 anomaly detection을 수행할 때, 기존에는 bottleneck의 크기를 hyper-parameter로 튜닝해야 했던 반면에, VAE의 경우에는 튜닝을 할 필요가 거의 없습니다.  \n",
    "\n",
    "- 신용 카드 데이터에 VAE(Variational Autoencoder)를 적용합니다. \n",
    "\n",
    "\n",
    "- 분포를 배우는 것이 좋은 점은,  \n",
    "    첫째, 데이터 및 노이즈 생성 프로세스를 명시적으로 모델링함으로써 VAE는 더 robust 하게 그 두가지를 분리하는 방법을 배울 수 있습니다.   \n",
    "    둘째, disentanglement constraint가 적용되면 잠재 공간이 더 해석 가능해집니다.    \n",
    "    셋째, 잠재 벡터를 샘플링하여 새 샘플을 생성하고 디코더를 통해 파이프할 수 있습니다.   \n",
    "    \n",
    "\n",
    "* disentanglement : latent space가 linear한 구조를 가지게 되어서 하나의 latent vector z 를 움직였을 때 정해진 어떠한 하나의 특성이 변경되게 만들고자 하는 것. 예를 들어, latent vector z 의 specific 한 값을 변경했을 때 생성되는 이미지는 하나의 특성들(머리카락 길이, 성별, 사람의 시선)만 영향을 주게 만들었다고 하면, 이 모델의 latent space는 disentanglement 하다고 말 할 수 있다.\n",
    "\n",
    "<sup>1</sup> [Building Autoencoders in Keras - Keras Blog](https://blog.keras.io/building-autoencoders-in-keras.html)  \n",
    "<sup>2</sup> [Variational Autoencoders with Tensorflow Probability Layers - Medium](https://medium.com/tensorflow/variational-autoencoders-with-tensorflow-probability-layers-d06c658931b7)   \n",
    "<sup>3</sup> [Google Colab VAE Interactive Example](https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb#scrollTo=9clSiUTiT3G1)  \n",
    "<sup>4</sup> [An, J., & Cho, S. (2015). Variational autoencoder based anomaly detection using reconstruction probability. Special Lecture on IE, 2, 1-18.](https://pdfs.semanticscholar.org/0611/46b1d7938d7a8dae70e3531a00fceb3c78e8.pdf)\n",
    "\n",
    "\n",
    "### Contents \n",
    "\n",
    "1. Variational Autoencoder 훈련\n",
    "2. 잠재 표현 시각화 (Visualize Latent Representations)\n",
    "3. VAE vs SVM\n",
    "4. 테스트 세트에 대한 평가\n",
    "5. Limitations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T12:03:00.896799Z",
     "iopub.status.busy": "2021-06-07T12:03:00.896474Z",
     "iopub.status.idle": "2021-06-07T12:03:00.901108Z",
     "shell.execute_reply": "2021-06-07T12:03:00.900299Z",
     "shell.execute_reply.started": "2021-06-07T12:03:00.896738Z"
    },
    "id": "RXd-JFGF7fqb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, \\\n",
    "                            precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdd18414d608713f44fb86d9ee8a9eae7fa77367",
    "id": "7sVQjS607fqc"
   },
   "source": [
    "## Raw Dataset\n",
    "\n",
    "model train 은 train set 만으로 합니다. test set은 최종 평가 때까지 사용되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "W8g_mu277fqc",
    "outputId": "cd289584-7be3-4f57-e3f0-b07ebd6d9463"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd9vWJgAKpSc"
   },
   "source": [
    "-  데이터 세트가 매우 불균형합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lv_9qemqKpSd",
    "outputId": "9d6a0949-aea8-4c35-c4ae-b824ac012a48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiwKNXqsKpSd",
    "outputId": "2ca0fcdf-0134-4ef3-bf96-5db07d57367e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 284,807\n",
      "Fraud = 0.17%\n",
      "Normal = 99.83%\n"
     ]
    }
   ],
   "source": [
    "fraud = (df['Class'] == 1).sum()\n",
    "normal = (df['Class'] == 0).sum()\n",
    "\n",
    "total = fraud + normal\n",
    "\n",
    "print(f\"Total = {total:,}\")\n",
    "print(f\"Fraud = {fraud/total*100:,.2f}%\")\n",
    "print(f\"Normal = {normal/total*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23wCkGDrKpSe"
   },
   "source": [
    "- Amount 필드는 로그 스케일로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9qBa4MkgKpSe"
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'Amount'] = np.log(df.loc[:, 'Amount'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eM-TssowKpSe"
   },
   "source": [
    "- class 1 이 너무 적으므로 통상적인 7:3 대신 5:5 비율로 train, test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "cbc89746d900392dbddef6a0906e0b4fefe88523",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlw9YCsp7fqd",
    "outputId": "364f0fed-2538-447c-faf1-6e558caad5e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142403, 30), (142404, 30), (142403,), (142404,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1).values , df['Class'].values, \n",
    "                                                    test_size=0.5, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK1VPhWmxjAQ",
    "outputId": "f8737d32-ae3d-4785-9abe-879ac9ba3163"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99825144, 0.00174856])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvKk0AdTKpSf",
    "outputId": "b61db426-8094-42c3-9ac5-07cb20775553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99829359, 0.00170641])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X4VX-zHJwou6"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ae6791f9f14094bf85111601d5a56c20a5fc34d",
    "id": "4xbpTJpN7fqf"
   },
   "source": [
    "## Train a Variational Autoencoder\n",
    "\n",
    "- latent variable의 prior는 latent dimension의 random unit multivariate normal vector(tfd.MultivariateNormalDiag) 로 설정 합니다.  \n",
    "\n",
    "- 인코더의 출력인 잠재 분포 parameter 는 0이 아닌 공분산을 가진 다변수 정규정규 분포로 선택 되었습니다. 이는 사기 거래와 정상적인 거래를 분리하는 데 영향을 미치고, 사기 거래의 공분산이 패턴을 가질 수 있기 때문입니다. 결과적으로 학습할 5 개의 distribution parameter가 있습니다 (2 개의 평균값 + 하삼각형의 2X2 공분산 행렬에서 가져온 공분산 값 3 개).  \n",
    "\n",
    "\n",
    "- 디코더의 출력인 데이터 분포 매개 변수는 feature-independent한 정규 분포를 따릅니다. (온라인에서 찾을 수 있는 대부분의 예제는 출력이 독립적인 베르누이 분포를 따르는 MNIST 데이터 세트와 같은 이진 이미지에 적용되었습니다.)  신용카드 데이터는 실수 값이며 일반적으로 정규 분포를 따르므로 정규 분포를 사용하여 출력을 모델링하는 것이 합리적입니다. (올바른 분포를 갖는 또 다른 중요한 의미는 훈련 중에 해당 로그 확률 손실을 제공한다는 것입니다. 예를 들어 이진 교차 엔트로피를 사용하여 실수 값 정규 분포를 훈련하는 것은 의미가 없습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFAU9qpzKpSg",
    "outputId": "970a7030-60b5-4994-b7ff-864217ea1082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142154, 30), (249, 30))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_fraud = X_train[y_train == 1]\n",
    "\n",
    "X_train_normal.shape, X_train_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDV2x0-OKpSh",
    "outputId": "f1601398-c024-4a44-ba1c-4f668d775e1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142161, 30), (243, 30))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_normal = X_test[y_test == 0]\n",
    "X_test_fraud = X_test[y_test == 1]\n",
    "\n",
    "X_test_normal.shape, X_test_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QCjKSeaGi1NE"
   },
   "outputs": [],
   "source": [
    "def encoder_model(input_dim, latent_dim):\n",
    "\n",
    "    prior = tfd.MultivariateNormalDiag(\n",
    "        loc=tf.zeros([latent_dim]),\n",
    "        scale_identity_multiplier=1.0)\n",
    "\n",
    "    encoder_input = Input(shape=(input_dim,))\n",
    "    x = Dense(20, activation=tf.nn.leaky_relu)(encoder_input)\n",
    "    x = Dense(15, activation=tf.nn.leaky_relu)(x)\n",
    "    x = Dense(tfp.layers.MultivariateNormalTriL.params_size(latent_dim), activation=None)(x)\n",
    "    encoded = tfp.layers.MultivariateNormalTriL(latent_dim, \n",
    "                        activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior))(x)\n",
    "    encoder = Model(encoder_input, encoded)\n",
    "    return encoder\n",
    "\n",
    "def decoder_model(latent_dim, input_dim):\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(15, activation=tf.nn.leaky_relu)(decoder_input)\n",
    "    x = Dense(20, activation=tf.nn.leaky_relu)(x)\n",
    "    x = Dense(tfp.layers.IndependentNormal.params_size(input_dim), activation=None)(x)\n",
    "    decoded = tfp.layers.IndependentNormal(input_dim)(x)\n",
    "\n",
    "    decoder = Model(decoder_input, decoded)\n",
    "    return decoder\n",
    "\n",
    "def vae_model(encoder, decoder):\n",
    "    vae = Model(inputs=encoder.inputs,\n",
    "                outputs=decoder(encoder.outputs[0]))\n",
    "\n",
    "    negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                loss=negloglik)\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ0jPt9gTYOX",
    "outputId": "1d281c4c-f6ca-453b-b778-62922dad5d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                620       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                320       \n",
      "                                                                 \n",
      " multivariate_normal_tri_l (  ((None, 5),              0         \n",
      " MultivariateNormalTriL)      (None, 5))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,255\n",
      "Trainable params: 1,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_normal.shape[1]\n",
    "\n",
    "latent_dim = 5\n",
    "encoder = encoder_model(input_dim, latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pwv_iOy8Tv-y",
    "outputId": "e384fec8-4716-424e-e534-b2a5838ffacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 15)                90        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                320       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 60)                1260      \n",
      "                                                                 \n",
      " independent_normal (Indepen  ((None, 30),             0         \n",
      " dentNormal)                  (None, 30))                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,670\n",
      "Trainable params: 1,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder_model(latent_dim, input_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "bd005b66ce9d41d43f6ff07674ebe64e3ba15717",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-hD_fRF7fqi",
    "outputId": "d875bdc2-0d8c-4818-e90e-d470726b4682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                620       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                320       \n",
      "                                                                 \n",
      " multivariate_normal_tri_l (  ((None, 5),              0         \n",
      " MultivariateNormalTriL)      (None, 5))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 30)                1670      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,925\n",
      "Trainable params: 2,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae = vae_model(encoder, decoder)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "9a80a22488211ff67043b170218cc2489b158ef4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86dI94jc7fqi",
    "outputId": "37d7e2f0-b66d-4ae1-99b3-17b5e9f9c63c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 8333948.5000 - val_loss: 12555.0439\n",
      "Epoch 2/1000\n",
      "1111/1111 [==============================] - 2s 2ms/step - loss: 87.0495 - val_loss: 242253.0938\n",
      "Epoch 3/1000\n",
      "1111/1111 [==============================] - 2s 2ms/step - loss: 133.1367 - val_loss: 12485.7285\n",
      "Epoch 4/1000\n",
      "1111/1111 [==============================] - 2s 2ms/step - loss: 83.6003 - val_loss: 239.5655\n",
      "Epoch 5/1000\n",
      "1111/1111 [==============================] - 2s 2ms/step - loss: 5317.7070 - val_loss: 75.7800\n",
      "Epoch 6/1000\n",
      "1111/1111 [==============================] - 2s 2ms/step - loss: 55.8829 - val_loss: 736.1483\n",
      "Epoch 7/1000\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 719.8972 - val_loss: 229.4386\n",
      "Epoch 8/1000\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 12943.2520 - val_loss: 1620.9728\n",
      "Epoch 9/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 48.6923 - val_loss: 319.3730\n",
      "Epoch 10/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 48.0186 - val_loss: 50.9792\n",
      "Epoch 11/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 49.1559 - val_loss: 576.8903\n",
      "Epoch 12/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 47.4477 - val_loss: 78.7065\n",
      "Epoch 13/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 47.6623 - val_loss: 85.4694\n",
      "Epoch 14/1000\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 47.3132 - val_loss: 59.4053\n",
      "Epoch 15/1000\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 54.7409 - val_loss: 46.8929\n",
      "Epoch 16/1000\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 46.8066 - val_loss: 47.9527\n",
      "Epoch 17/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 46.4475 - val_loss: 47.7688\n",
      "Epoch 18/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 100.6574 - val_loss: 48.3941\n",
      "Epoch 19/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 45.7794 - val_loss: 793.7065\n",
      "Epoch 20/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 45.5640 - val_loss: 45.1576\n",
      "Epoch 21/1000\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 46.2507 - val_loss: 45.0209\n",
      "Epoch 22/1000\n",
      " 679/1111 [=================>............] - ETA: 0s - loss: 46.5631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13900/3050711001.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                              patience=10, verbose=0, restore_best_weights=True)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m history = vae.fit(X_train_normal, X_train_normal, \n\u001b[0m\u001b[0;32m     12\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_normal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_normal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 1000\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='bestmodel.h5', verbose=0, save_best_only=True)\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                             patience=10, verbose=0, restore_best_weights=True)\n",
    "\n",
    "history = vae.fit(X_train_normal, X_train_normal, \n",
    "                  epochs=max_epochs, batch_size=128, shuffle=True,\n",
    "                  verbose=1, validation_data=(X_test_normal, X_test_normal),\n",
    "                  callbacks=[earlystopper, checkpointer])\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "OQW0KDLVCoo6",
    "outputId": "aeeead00-8c24-4b4b-c944-2a48627e5a68"
   },
   "outputs": [],
   "source": [
    "plt.plot([v for v in history.history['val_loss'] if v < 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8838e8cf12d64ad6189a20f6d1dbe2feb0a77682",
    "id": "Du1qgiXv7fqi"
   },
   "source": [
    "동일한 숫자의 입력을 정상거래와 사기거래에서 sampling 하여 재구성 분포를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pyCSeCYR9DT",
    "outputId": "50dcef36-f2ef-45fb-c51a-2096e04ee1cd"
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(X_train_normal), 250, replace=False)\n",
    "Nom_data = X_train_normal[idx]\n",
    "Nom_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Idsn4RRmSBk8",
    "outputId": "3aefbc2a-1d04-4a62-86e3-2360ef89bc31"
   },
   "outputs": [],
   "source": [
    "Nom_pred = vae.predict(Nom_data)    # AE 결과값 \n",
    "Nom_pred_mse = np.mean(np.power(Nom_data - Nom_pred, 2), axis=1) # input - output 간의 MSE 구하기\n",
    "\n",
    "print('Normal Metric')\n",
    "Nom_pred_mse_df = pd.DataFrame({'Normal_mse':Nom_pred_mse})\n",
    "print(Nom_pred_mse_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pK1yv87vSKVp",
    "outputId": "6aaf3e0e-0188-46a3-9995-74f75684ea12"
   },
   "outputs": [],
   "source": [
    "# Abnormal data \n",
    "ANom_pred = vae.predict(X_train_fraud)   # AE 결과값 \n",
    "ANom_pred_mse = np.mean(np.power(X_train_fraud - ANom_pred, 2), axis=1) # input - output 간의 MSE 구하기\n",
    "\n",
    "print('Anomaly Metric')\n",
    "ANom_pred_mse_df = pd.DataFrame({'Anomaly_mse':ANom_pred_mse})\n",
    "print(ANom_pred_mse_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLU3fwifwovA"
   },
   "source": [
    "### MSE 분포 시각화 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "jXLxERDsSRB0",
    "outputId": "579372ce-55a5-43dd-9bb1-3fbb4cd6ce4b"
   },
   "outputs": [],
   "source": [
    "plt.title('MSE compare') \n",
    "plt.hist(Nom_pred_mse, bins=10, color='blue', histtype='step', label='normal') \n",
    "plt.hist(ANom_pred_mse, bins=10, color='red', histtype='step', label='abnormal') \n",
    "plt.xlabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "bBn-OXLgSWQF",
    "outputId": "aaa808a7-444f-4340-8aec-21d21be50ad0"
   },
   "outputs": [],
   "source": [
    "plt.boxplot([Nom_pred_mse, ANom_pred_mse])\n",
    "plt.title('Normal vs Fraud')\n",
    "plt.xticks(ticks=[1, 2], labels=['Normal', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3aa3460670596e3bb58666bc24817b20861f46b",
    "id": "KKZC-tJv7fqj"
   },
   "source": [
    "## Visualize Latent Representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d7edc564bfd9a96dbc804216edd707b495ba0b08",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Mh82Rsxr7fqj",
    "outputId": "407e2ba7-17e6-4af2-a9b1-a2ccd4bcb06d"
   },
   "outputs": [],
   "source": [
    "latent_x_mean = encoder(X_test).mean()\n",
    "plt.scatter(latent_x_mean[:, 0], latent_x_mean[:, 1], c=y_test, cmap='RdYlGn_r', s=2)\n",
    "plt.title('latent means')\n",
    "plt.ylabel('mean[1]')\n",
    "plt.xlabel('mean[0]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09dbe144248f5f8f8c2754de653149fb2608d551",
    "id": "h6doEwpY7fqj"
   },
   "source": [
    "원점 [0,0] 평균 벡터 주변에서 사기와 사기가 아닌 트랜잭션 사이에는 분명한 구분이 있습니다. 이는 VAE가 의미있는 것을 학습하고 있다는 신호입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c5372f7b09feb79dd06d2c7feca5cc0890b4a136",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "jIgo_BMJ7fqk",
    "outputId": "54668c2a-7d2e-4720-dac4-6ac80261d667"
   },
   "outputs": [],
   "source": [
    "latent_x_std = encoder(X_test).stddev()\n",
    "plt.scatter(latent_x_std[:, 0], latent_x_std[:, 1], c=y_test, cmap='RdYlGn_r', s=2)\n",
    "plt.title('latent standard deviations')\n",
    "plt.ylabel('stddev[1]')\n",
    "plt.xlabel('stddev[0]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b982ca31566b9cb7d81b390816e9b20ccedcc88",
    "id": "ZdOw2PUh7fqk"
   },
   "source": [
    "빨간색으로 표시된 사기 거래의 표준 편차가 훨씬 더 흩어져 있고 사기 거래가 불규칙한 경향이 있다는 직관과 일치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9edccf3ad419e137bf74fe324de2d743b06618a4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "B11ssDzc7fqk",
    "outputId": "ecdc72c2-eeab-4fa4-da2f-38baca17041b"
   },
   "outputs": [],
   "source": [
    "latent_x = encoder(X_test).sample()\n",
    "plt.scatter(latent_x[:, 0], latent_x[:, 1], c=y_test, cmap='RdYlGn_r', s=2)\n",
    "plt.title('latent vector samples')\n",
    "plt.ylabel('z[1]')\n",
    "plt.xlabel('z[0]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68c76ab08542180d937ac46a872259199da35310",
    "id": "2o0u9O8G7fqk"
   },
   "source": [
    "샘플된 잠재 벡터 z입니다. 클러스터링 및 scattering은 이전 관찰과 일치합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slT6doi5WNb6"
   },
   "source": [
    "##  Reconstruction error threshold\n",
    "- 정상 data 로만 train 한 vae model 의 재구성 결과의 원본과의 mse 차이를 기준으로 사기 거래 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKHizXGgWXoC"
   },
   "outputs": [],
   "source": [
    "predictions = vae.predict(X_train)\n",
    "\n",
    "mse = np.mean(np.power(X_train - predictions, 2), axis=1)\n",
    "\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse, 'true_class': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "KyocyCtTWXeY",
    "outputId": "81fee91d-e2b6-413c-a111-9220cde39d26"
   },
   "outputs": [],
   "source": [
    "desc = error_df.groupby('true_class').describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mh_FGtrXjZn"
   },
   "source": [
    "위에서 보듯 사기성이 아닌 거래의  오류는 사기성 거래 보다 낮습니다.\n",
    "\n",
    "- mean + 3*std를 threshold로 사용하여 test set의 재구성 error(squared error)가 threshold 보다 크면 fraud 거래로 분류합니다.  \n",
    "- 1 std - 68%, 2 std - 96%, 3 std - 99.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jWu9P2qWXRq",
    "outputId": "7eab00f4-9192-4144-8f18-a71dc0133722"
   },
   "outputs": [],
   "source": [
    "mean = desc['reconstruction_error']['mean'][0]\n",
    "std = desc['reconstruction_error']['std'][0]\n",
    "thresholds = {'3sigma': mean + 3*std, \n",
    "              '2.5sigma': mean + 2.5*std, \n",
    "              \"2sigma\": mean + 2*std}\n",
    "mean, std, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "nLfNInzVYtNE",
    "outputId": "0f9bd754-52b5-411e-91f5-a7174e2f4ccc"
   },
   "outputs": [],
   "source": [
    "ths = sorted(thresholds.items(), key=lambda kv: kv[1])\n",
    "\n",
    "for k, threshold in ths:\n",
    "    \n",
    "    test_predictions = vae.predict(X_test)\n",
    "    mse = np.mean(np.power(X_test - test_predictions, 2), axis=1)\n",
    "    y_pred = [(lambda er: 1 if er > threshold else 0)(er) for er in mse]\n",
    "\n",
    "    print(\"Precision {:.2f}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"Recall {:.2f}\".format(recall_score(y_test, y_pred)))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    ax = sns.heatmap(cm, annot=True, fmt=',')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.xaxis.set_ticklabels(['Normal', 'Fraud'])\n",
    "    ax.yaxis.set_ticklabels(['Normal', 'Fraud'])\n",
    "    ax.set(yticks=[0.5, 1.5], xticks=[0.5, 1.5])\n",
    "    ax.set_title(k)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "250_fraud_detection_with_variational_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
